{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627017cc-0cc5-434d-9966-07dab9c0f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from tqdm.notebook import tqdm  # Use the notebook-friendly version of tqdm\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5750d0-a0e6-4297-a16e-fd85605d6ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='key.env')     #Get api key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a6c9a5-40fd-4219-803a-eb5486aebfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- API Initialization ---\n",
    "GPT_MODEL = \"o4-mini\"\n",
    "try:\n",
    "    client = openai.OpenAI()\n",
    "    print(\"OpenAI client initialized successfully.\")\n",
    "except openai.OpenAIError:\n",
    "    print(\"Error: OpenAI API key not found. Make sure it's set as an environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a543c7-c719-492f-a830-7d75979200b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured to process 1 files.\n"
     ]
    }
   ],
   "source": [
    "# --- Create a list of dictionaries, one for each file to process ---\n",
    "files_to_process = [\n",
    "    # {\n",
    "    #     'name': 'Training Set',\n",
    "    #     'path': 'zmean_train_80_with_gpt_reasonings.tsv'\n",
    "    # },\n",
    "    # {\n",
    "    #     'name': 'Development Set',\n",
    "    #     'path': 'zmean_dev_10_with_gpt_reasonings.tsv' # Assuming this is the dev set path\n",
    "    # },\n",
    "    {\n",
    "        'name': 'Test Set',\n",
    "        'path': 'new_portion_processed/zmean_test_10.tsv'\n",
    "    }\n",
    "    # You can add more files here in the future\n",
    "]\n",
    "\n",
    "print(f\"Configured to process {len(files_to_process)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a997bc-342c-43f4-b9c9-91d53381c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions are defined and ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define Helper Functions\n",
    "\n",
    "# --- The System Prompt ---\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an annotator for the quality of machine translation. You have a pair of sentences and a score indicating the translation quality. Your task is to identify errors, assess the quality of the translation, and explain why the translation gets this score.\n",
    "The score is in range [-2, 2], -2 signifies that the translation is at the worst quality, inhibiting comprehension of the text; 2 signifies that the translation is at the best quality, fluent and accurate, used proper terms. The scores in between indicates major or minor errors: Major errors disrupt the flow, but what the text is trying to say is still understandable. Minor errors are technically errors, but they do not disrupt the flow or hinder comprehension. The score's position within the -2 to 2 range indicates subtle, yet significant, differences in translation quality.\n",
    "Your response must be direct and concise. Do not include any headers (like 'Assessment' or 'Reasoning'), bullet points, or concluding summary paragraphs (like 'Overall, ...'). Output only the core reasoning as a single, dense paragraph.\n",
    "\"\"\"\n",
    "\n",
    "# --- The Worker Function for multithreading ---\n",
    "def get_explanation_for_row(row_data):\n",
    "    index, row = row_data\n",
    "    src, mt, score = row['src'], row['mt'], row['zmean']\n",
    "    user_prompt = f\"Source: {src}\\nTranslation: {mt}\\nScore:{score}\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            max_completion_tokens=3500\n",
    "        )\n",
    "        return index, response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error on index {index}: {e}\")\n",
    "        return index, None\n",
    "\n",
    "# --- Main logic wrapped in functions ---\n",
    "def analyze_and_report(file_path):\n",
    "    \"\"\"Loads a file and prints a report of missing entries.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}. Skipping.\")\n",
    "        return None, None\n",
    "        \n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    missing_df = df[df['gpt_explanation'].isna()].copy()\n",
    "    \n",
    "    print(f\"  Total rows: {len(df)}\")\n",
    "    print(f\"  Missing explanations: {len(missing_df)}\")\n",
    "    \n",
    "    return df, missing_df\n",
    "\n",
    "def fix_missing_entries(df, missing_df, file_path):\n",
    "    \"\"\"Takes a dataframe with missing entries and fixes them.\"\"\"\n",
    "    rows_to_process = list(missing_df.iterrows())\n",
    "    MAX_WORKERS = 50\n",
    "\n",
    "    print(f\"  Starting to fetch {len(rows_to_process)} missing explanations with {MAX_WORKERS} workers...\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        results_iterator = executor.map(get_explanation_for_row, rows_to_process)\n",
    "        for index, explanation in tqdm(results_iterator, total=len(rows_to_process), desc=\"  Fixing entries\"):\n",
    "            if explanation:\n",
    "                df.loc[index, 'gpt_explanation'] = explanation\n",
    "    \n",
    "    # --- Final verification and save ---\n",
    "    final_missing_count = df['gpt_explanation'].isna().sum()\n",
    "    print(f\"\\n  Fixing process complete. Remaining missing rows: {final_missing_count}\")\n",
    "    print(f\"  Saving updated data back to: {file_path}\")\n",
    "    df.to_csv(file_path, sep='\\t', index=False)\n",
    "    print(\"  File saved successfully.\")\n",
    "\n",
    "print(\"Helper functions are defined and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa1b0d21-7114-4088-ad78-4ab26bc267be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: Test Set (new_portion_processed/zmean_test_10.tsv)\n",
      "============================================================\n",
      "  Total rows: 14477\n",
      "  Missing explanations: 2\n",
      "  Starting to fetch 2 missing explanations with 50 workers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31378618bbed424ea591d98198364bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Fixing entries:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Fixing process complete. Remaining missing rows: 0\n",
      "  Saving updated data back to: new_portion_processed/zmean_test_10.tsv\n",
      "  File saved successfully.\n",
      "\n",
      "============================================================\n",
      "All configured files have been processed.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Main Execution Loop\n",
    "\n",
    "for file_info in files_to_process:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Processing: {file_info['name']} ({file_info['path']})\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Analyze the file and get the report\n",
    "    df, missing_df = analyze_and_report(file_info['path'])\n",
    "    \n",
    "    # Step 2: If there are missing rows, fix them\n",
    "    if df is not None and not missing_df.empty:\n",
    "        fix_missing_entries(df, missing_df, file_info['path'])\n",
    "    elif df is not None:\n",
    "        print(\"  ðŸŽ‰ No missing entries to fix for this file.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All configured files have been processed.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72904607-64fb-4ee8-ac57-63524bef9b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Validation Check ---\n",
      "\n",
      "Verifying file: 'Test Set'...\n",
      "   SUCCESS: No empty 'gpt_explanation' entries found.\n",
      "\n",
      "==================================================\n",
      " Validation complete. All specified files look good!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Final Validation Check ---\")\n",
    "\n",
    "# This flag will help us summarize the final result\n",
    "all_files_ok = True\n",
    "\n",
    "# We reuse the 'files_to_process' list you defined in a previous cell.\n",
    "# This loop will check each file in that list.\n",
    "for file_info in files_to_process:\n",
    "    file_path = file_info['path']\n",
    "    file_name = file_info['name']\n",
    "    \n",
    "    print(f\"\\nVerifying file: '{file_name}'...\")\n",
    "\n",
    "    # Check if the file exists before trying to read it\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"   ERROR: File not found at {file_path}\")\n",
    "        all_files_ok = False\n",
    "        continue  # Move to the next file in the list\n",
    "\n",
    "    try:\n",
    "        # Load the data file\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        \n",
    "        # Check for any null/empty values in the 'gpt_explanation' column\n",
    "        # .isna() detects NaN, None, etc. .sum() counts them.\n",
    "        missing_count = df['gpt_explanation'].isna().sum()\n",
    "\n",
    "        # Report the result for the current file\n",
    "        if missing_count == 0:\n",
    "            print(f\"   SUCCESS: No empty 'gpt_explanation' entries found.\")\n",
    "        else:\n",
    "            print(f\"   WARNING: Found {missing_count} empty 'gpt_explanation' entries in this file.\")\n",
    "            all_files_ok = False # Mark that at least one file has issues\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR: Could not read or process the file. Error: {e}\")\n",
    "        all_files_ok = False\n",
    "\n",
    "# --- Print a final summary message ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if all_files_ok:\n",
    "    print(\" Validation complete. All specified files look good!\")\n",
    "else:\n",
    "    print(\"Validation complete. One or more files have issues or were not found.\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9901ae4d-4247-4867-b092-be66228dc4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading full dataset from: zmean_train_80_with_gpt_reasonings.tsv\n",
      " Full dataset loaded successfully. Total rows: 115809\n",
      "Sliced the first 500 rows to create the toy dataset.\n",
      "--------------------------------------------------\n",
      " Success! New toy dataset saved to: toy_train_with_reasoning.tsv\n",
      "   It contains 500 rows.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cut out 500 lines and make a toy set with reasoning\n",
    "# --- Configuration ---\n",
    "# 1. Define the path to your full training set file with reasonings.\n",
    "#    Please verify this path is correct relative to your notebook's location.\n",
    "input_file_path = 'zmean_train_80_with_gpt_reasonings.tsv'\n",
    "\n",
    "# 2. Define the path for the new toy dataset you want to create.\n",
    "output_file_path = 'toy_train_with_reasoning.tsv'\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(f\"Reading full dataset from: {input_file_path}\")\n",
    "\n",
    "# Check if the input file exists before proceeding\n",
    "\n",
    "try:\n",
    "    # Load the entire dataset from the TSV file\n",
    "    full_df = pd.read_csv(input_file_path, sep='\\t')\n",
    "    print(f\" Full dataset loaded successfully. Total rows: {len(full_df)}\")\n",
    "\n",
    "    # Check if the dataset has at least 500 rows\n",
    "    if len(full_df) >= 500:\n",
    "        # Slice the first 500 rows to create the toy dataset\n",
    "        toy_df = full_df.head(500)\n",
    "        print(f\"Sliced the first 500 rows to create the toy dataset.\")\n",
    "\n",
    "        # Save the new toy DataFrame to a new TSV file\n",
    "        # index=False prevents pandas from writing row numbers into the file\n",
    "        toy_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(f\" Success! New toy dataset saved to: {output_file_path}\")\n",
    "        print(f\"   It contains {len(toy_df)} rows.\")\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        print(f\" Warning: The source file has only {len(full_df)} rows, which is less than 500. A full toy set could not be created.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" An error occurred while processing the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c3fac-246b-4656-a2f8-0fa011ce43d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
